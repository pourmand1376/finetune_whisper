{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26419cca-d936-4261-b2fa-b710b5fe6c32",
   "metadata": {},
   "source": [
    "!pip install huggingface-cli\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b199d9b-632a-4359-b2ca-83ff9b01eddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 8.17k/8.17k [00:00<00:00, 5.84MB/s]\n",
      "Downloading readme: 100%|██████████| 12.3k/12.3k [00:00<00:00, 6.56MB/s]\n",
      "Downloading extra modules: 100%|██████████| 3.74k/3.74k [00:00<00:00, 6.99MB/s]\n",
      "Downloading extra modules: 100%|██████████| 77.3k/77.3k [00:00<00:00, 249kB/s]\n",
      "HF google storage unreachable. Downloading and preparing it from source\n",
      "Downloading data: 100%|██████████| 14.6k/14.6k [00:00<00:00, 9.25MB/s]\n",
      "Downloading data: 100%|██████████| 710M/710M [03:59<00:00, 2.96MB/s]  \n",
      "Downloading data: 100%|██████████| 327M/327M [02:00<00:00, 2.70MB/s] \n",
      "Downloading data: 100%|██████████| 409M/409M [02:35<00:00, 2.63MB/s] \n",
      "Downloading data: 100%|██████████| 700M/700M [04:11<00:00, 2.79MB/s]  \n",
      "Downloading data: 100%|██████████| 593M/593M [03:37<00:00, 2.72MB/s]  \n",
      "Downloading data: 100%|██████████| 6.74M/6.74M [00:04<00:00, 1.46MB/s]\n",
      "Downloading data: 100%|██████████| 2.43M/2.43M [00:01<00:00, 1.50MB/s]\n",
      "Downloading data: 100%|██████████| 2.48M/2.48M [00:01<00:00, 1.53MB/s]\n",
      "Downloading data: 100%|██████████| 7.94M/7.94M [00:03<00:00, 2.18MB/s]\n",
      "Downloading data: 100%|██████████| 3.70M/3.70M [00:01<00:00, 1.87MB/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
      "Reading metadata...: 13799it [00:00, 137980.26it/s]\u001b[A\n",
      "Reading metadata...: 28810it [00:00, 137512.53it/s]\u001b[A\n",
      "Generating train split: 28810 examples [00:06, 4181.35 examples/s]\n",
      "Generating validation split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 10547it [00:00, 167424.20it/s]\n",
      "Generating validation split: 10547 examples [00:02, 3918.13 examples/s]\n",
      "Generating test split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 10547it [00:00, 171718.08it/s]\n",
      "Generating test split: 10547 examples [00:02, 3990.19 examples/s]\n",
      "Generating other split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
      "Reading metadata...: 16309it [00:00, 163083.16it/s]\u001b[A\n",
      "Reading metadata...: 33390it [00:00, 163295.54it/s]\u001b[A\n",
      "Generating other split: 33390 examples [00:07, 4198.48 examples/s]\n",
      "Generating invalidated split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 14527it [00:00, 168071.58it/s]\n",
      "Generating invalidated split: 14527 examples [00:03, 4081.91 examples/s]\n",
      "/home/user/.pyenv/versions/3.10.13/lib/python3.10/site-packages/datasets/load.py:2483: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "/home/user/.pyenv/versions/3.10.13/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for mozilla-foundation/common_voice_16_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_16_0\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
      "        num_rows: 39357\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
      "        num_rows: 10547\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_16_0\", \"fa\", split=\"train+validation\", use_auth_token=True,cache_dir='cv')\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_16_0\", \"fa\", split=\"test\", use_auth_token=True,cache_dir='cv')\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c90178d-417a-40a5-8fb2-3c71266599bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'sentence', 'variant'],\n",
      "        num_rows: 39357\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'sentence', 'variant'],\n",
      "        num_rows: 10547\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc1da24-6279-484d-bc5c-2f0f115dc849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.pyenv/versions/3.10.13/lib/python3.10/site-packages/transformers/utils/hub.py:122: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "preprocessor_config.json: 100%|██████████| 185k/185k [00:00<00:00, 478kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-medium\",cache_dir='v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f770b6fb-dc05-41fe-bd47-ba08ca36797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 805/805 [00:00<00:00, 2.04MB/s]\n",
      "vocab.json: 100%|██████████| 836k/836k [00:00<00:00, 1.44MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.48M/2.48M [00:01<00:00, 2.40MB/s]\n",
      "merges.txt: 100%|██████████| 494k/494k [00:00<00:00, 3.81MB/s]\n",
      "normalizer.json: 100%|██████████| 52.7k/52.7k [00:00<00:00, 29.9MB/s]\n",
      "added_tokens.json: 100%|██████████| 34.6k/34.6k [00:00<00:00, 31.5MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 2.08k/2.08k [00:00<00:00, 5.66MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-medium\", language=\"Persian\", task=\"transcribe\",cache_dir='v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05026259-5aaf-4be3-a083-e483a0dc9dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\", language=\"Persian\", task=\"transcribe\",cache_dir='v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db0a1d2-80bc-4ac6-b4cb-c570cfa25d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': {'path': '/home/user/app/cv/downloads/extracted/3afd7baca3d7c3b86f492c299f17cedab6e37c6d1b71c0ae4ab0e146df03a90e/fa_train_0/common_voice_fa_27232035.mp3', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "       -3.53045198e-06, -2.47697017e-06, -1.12267401e-06]), 'sampling_rate': 48000}, 'sentence': 'تعداد آنها در حال تقلیل است.', 'variant': ''}\n"
     ]
    }
   ],
   "source": [
    "print(common_voice[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b253cc-9721-4e7c-96d4-bbad2ae240ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "121a36db-8af4-4f97-bc85-cf110db9847e",
   "metadata": {
    "id": "87122d71-289a-466a-afcf-fa354b18946b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': {'path': '/home/user/app/cv/downloads/extracted/3afd7baca3d7c3b86f492c299f17cedab6e37c6d1b71c0ae4ab0e146df03a90e/fa_train_0/common_voice_fa_27232035.mp3', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "        5.94547600e-07, -3.05834692e-06, -3.57083627e-06]), 'sampling_rate': 16000}, 'sentence': 'تعداد آنها در حال تقلیل است.', 'variant': ''}\n"
     ]
    }
   ],
   "source": [
    "print(common_voice[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2060d-0c1d-474e-9677-a3a52d949c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8feb0bd-5230-4458-bc86-24fce1b5e6e5",
   "metadata": {
    "id": "6525c478-8962-4394-a1c4-103c54cce170"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c51c3c3b-3b01-47ad-af1b-bcbff1b5bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63065c49-41ba-4706-aaeb-9362d2eab971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=10): 100%|██████████| 39357/39357 [35:20<00:00, 18.56 examples/s] \n",
      "Map (num_proc=10): 100%|██████████| 10547/10547 [09:18<00:00, 18.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af1c01be-9e18-4fc1-b65c-6c5bcba2663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (76/76 shards): 100%|██████████| 39357/39357 [00:38<00:00, 1026.23 examples/s]\n",
      "Saving the dataset (21/21 shards): 100%|██████████| 10547/10547 [00:09<00:00, 1061.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "common_voice.save_to_disk('common_voice_processed.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1948a0-a13e-498b-b2a9-1d7643cbd85b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
